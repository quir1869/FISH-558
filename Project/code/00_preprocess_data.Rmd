---
title: "Seafood Analysis"
author: "Connor Quiroz"
date: "2024-11-15"
output: html_document
---

# Setup / Load in Packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# General data cleaning + visualization + analysis packages
library(tidyverse)
library(ggformula)
library(countrycode)
library(data.table)
library(arrow)
library(cowplot)
library(RColorBrewer)

# Map creation
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)

# Load in packages needed for ARTIS
library(devtools)
library(tidytext)
# devtools::install_github("davidsjoberg/ggsankey")
library(ggsankey)
# devtools::install_github("Seafood-Globalization-Lab/exploreARTIS@v1.0.0", dependencies = TRUE)
library(exploreARTIS)
library(here)
knitr::opts_knit$set(root.dir = paste0(here(),"/code"))
```

# Data Cleaning

```{r new preprocess future climate data}
if (!file.exists("../output/future_climate_joined_2025_10_01.csv")) {
  file_names <- list.files(path = "../data/exposure/dbem_delta_mcp/", pattern = "\\.csv", full.names = TRUE)

# # Obtain species lookup key (will be used in loop join)
species_names <- fread("../data/exposure/dbem_spp_list.csv")

# # initiate empty df
df <- data.frame()

for (i in 1:length(file_names)) {
  # Read in i'th species file in loop
  df_i <- fread(file_names[i])
  
  if (nrow(df_i) > 0) {
    df_i <- left_join(df_i, species_names, by = "taxon_key")
    
    # Select only certain variables for certain years and pivot wider
    df_i <- df_i %>%
      mutate(taxon_name = str_to_lower(taxon_name)) %>%
      select(taxon_name, eez_name, ssp, mean_mcp_delta_2030) %>%
      pivot_wider(names_from = ssp, values_from = mean_mcp_delta_2030)
    
    # Combine all species observations into one file
    df <- df %>%
      bind_rows(df_i)
  }
  
}

# Obtain previous state on dataframe (to get unmatched)
df_preprocessed <- df

# Convert eez variable countries to iso3c codes
df <- df %>%
  mutate(eez_name = countrycode(eez_name, 
                                origin = "country.name",
                                destination = "iso3c"))

# Rename country variable so it can be joined
df <- df %>%
  rename(eez_iso3c = "eez_name",
         sciname = "taxon_name")
#
# # Write joined future cimate data to .csv
write_csv(df, "../output/future_climate_joined_2025_10_01.csv")
#
# # # See how many countries were not matches
sum(is.na(df$eez_iso3c))
#
# # # Number of countries that properly got matched
length(unique(df$eez_iso3c))
#
# # # Unmatched countries via countrycode
unmatched_countries <- unique(df_preprocessed$eez_name[c(which(is.na(df$eez_iso3c)))])
#
# # # Only keep rows in preprocessed dataset that are unmatched countries
df_preprocessed <- df_preprocessed %>%
  filter(eez_name %in% unmatched_countries)
#
# # Territories that were not matched via countrycode (Tokelau & Svalbard Isl.)
df_preprocessed %>% distinct(eez_name)

####################################

# # Get country names out of parenthesis with string detects
for (i in seq_along(df_preprocessed$eez_name)) {

  if (xor(str_detect(df_preprocessed$eez_name[i], "\\("), str_detect(df_preprocessed$eez_name[i], "Yemen"))) {
    split_string <- str_split(df_preprocessed$eez_name[i], "\\(")
    split_string <- str_split(split_string[[1]][2], "\\)")
    df_postprocessed$eez_name[i] <- split_string[[1]][1]
  }
  else if (str_detect(df_preprocessed$eez_name[i], "Yemen")) {
    df_postprocessed$eez_name[i] <- str_split(df_preprocessed$eez_name[i], "\\ \\(")[[1]][1]
  }

}
#
# # Convert previously unmatched countries to iso3c
for (i in 1:length(df$eez_name)) {
  df_postprocessed$eez_name[i] <- countrycode(df_postprocessed$eez_name[i], origin = 'country.name', destination = 'iso3c')
}

# Rename country variable so it can be joined
df_postprocessed <- df_postprocessed %>%
  rename(eez_iso3c = "eez_name")

# Add in unmatched countries (now all countries are matched)
df <- bind_rows(df, df_postprocessed)
}
```

```{r data cleaning for hdi + consumption data}
# Read in cosnumption data
consumption <- read_parquet("../data/example_consumption_eez_2024_12_06.parquet") %>%
  mutate(sciname_hs_modified = case_when(
    is.na(sciname_hs_modified) ~ sciname,
    TRUE ~ sciname_hs_modified
  )) # Get rid of NA scinames

# Read in sciname data (for joining to scinames of future climate)
sciname <- read_csv("../data/sciname.csv")
```

```{r look at how many consumed ARTIS species are invasive}
# Load in function for identifying which ARTIS species are invasive
source("../R/get_invasives.R")

# Get ARTIS scientific names
artis_scinames <- sciname %>%
  distinct(sciname) %>%
  pull(sciname)

# Get invasive list from fb/slb - last date acquired: 8/27/2025
# fb_introductions <- rfishbase::introductions(server = "fishbase")
# write_parquet(fb_introductions, "../data/fb_slb_data/fb_introductions.parquet")

# ... same thing but for sealifebase - last date acquired: 8/27/2025
# slb_introductions <- rfishbase::introductions(server = "sealifebase")
# write_parquet(slb_introductions, "../data/fb_slb_data/slb_introductions.parquet")

# Read in introductions data
fb_introductions <- read_parquet("../data/fb_slb_data/fb_introductions.parquet")
slb_introductions <- read_parquet("../data/fb_slb_data/slb_introductions.parquet")

# Get fb/slb species codes
fb_species_codes <- read_parquet("../data/fb_slb_data/fb_species_codes.parquet")
slb_species_codes <- read_parquet("../data/fb_slb_data/slb_species_codes.parquet")

# Import file for correcting fb/slb territory names to iso3c 
territory_corrections <- read_csv("../data/fb_slb_data/fb_slb_territory_corrections.csv") %>%
  select(c(fb_slb_territories_iso3c, fb_slb_unmatched_territories, "associated_territory_country_iso3c" = "associated_country_iso3c...7", "associated_country_iso3c" = "associated_country_iso3c...5"))

sciname_corrections <- read_csv("../data/fb_slb_data/fb_slb_territory_corrections.csv") %>%
  select(fb_slb_scientific_name, new_sciname)
  
# Get invasive species for fishbase and sealifebase
invasives <- get_invasives(introductions_data = fb_introductions, species_codes_data = fb_species_codes)

# Write to parquet
write_parquet(invasives, "../output/invasives.parquet")
```

```{r disaggregate future climate measurements}
# Read in future climate data
df <- read_csv("../output/future_climate_joined_2025_10_01.csv")

# Group by species and by region so that only species is taken into consideration
df1 <- df %>%
  drop_na() %>%
  group_by(eez_iso3c, sciname) %>%
  summarize(`ssp126` = mean(`ssp126`),
            `ssp585` = mean(`ssp585`))

sciname_taxa <- sciname %>% 
  mutate(taxa_level = case_when(
    sciname == kingdom ~ "kingdom",
    sciname == phylum ~ "phylum",
    sciname == superclass ~ "superclass",
    sciname == class ~ "class",
    sciname == order ~ "order",
    sciname == family ~ "family",
    sciname == subfamily ~ "subfamily",
    sciname == genus ~ "genus",
    str_detect(sciname, " ") ~ "species"
  )) %>%
  mutate(species = case_when(
    str_count(sciname, " ") == 1 ~ word(sciname, 2),
    TRUE ~ NA_character_
  )) %>% # Add species column name
  relocate(species, .before = genus) %>% 
  select(-common_name, -isscaap)

# Filter out consumption data so it only includes the future names
consumption_future <- consumption %>%
  filter(year == 2019)

# Join consumption to sciname data
consumption_sciname <- left_join(consumption_future, sciname_taxa, by = c("sciname_hs_modified" = "sciname"))

# Join consumption/sciname by sciname / eez
test_data <- left_join(consumption_sciname, df1, by = c("eez_iso3c", "sciname_hs_modified" = "sciname"))

# Create function to average across across every future climate sciname for every taxa level names (e.g., order, class, genus)
compute_taxa_averages <- function(df, tax_level) {
  df %>%
    filter(!is.na(ssp126) | !is.na(ssp585)) %>%  # Keep only true species
    group_by(eez_iso3c, !!sym(tax_level)) %>%    # Group by EEZ & chosen tax level
    summarise(
      avg_ssp126 = mean(ssp126, na.rm = TRUE),
      avg_ssp585 = mean(ssp585, na.rm = TRUE),
      .groups = "drop"  # Prevent unexpected grouping behavior
    )
}

# Compute averages across all taxa levels
averages_genus <- compute_taxa_averages(test_data, "genus") %>%
  rename(taxa_name = genus) %>%
  mutate(taxa_level = "genus")

averages_subfamily <- compute_taxa_averages(test_data, "subfamily") %>%
  rename(taxa_name = subfamily) %>%
  mutate(taxa_level = "subfamily")

averages_family <- compute_taxa_averages(test_data, "family") %>%
  rename(taxa_name = family) %>%
  mutate(taxa_level = "family")

averages_order <- compute_taxa_averages(test_data, "order") %>%
  rename(taxa_name = order) %>%
  mutate(taxa_level = "order")

averages_class <- compute_taxa_averages(test_data, "class") %>%
  rename(taxa_name = class) %>%
  mutate(taxa_level = "class")

averages_phylum <- compute_taxa_averages(test_data, "phylum") %>%
  rename(taxa_name = phylum) %>%
  mutate(taxa_level = "phylum")

# Combine all aggregated results into a single lookup table:
lookup_table <- bind_rows(averages_genus, averages_subfamily, averages_family, averages_order, averages_class, averages_phylum)


# Currently: averaging future climate data to higher values adds ~ 300,000 rows
interpolated_future_data <- left_join(test_data, lookup_table, by = c("eez_iso3c", "sciname_hs_modified" = "taxa_name", "taxa_level")) %>%
  mutate(
    ssp126 = if_else(is.na(ssp126), avg_ssp126, ssp126), # Interpolate non-true species to averages created from original future climate data based on true species
    ssp585 = if_else(is.na(ssp585), avg_ssp585, ssp585)
  ) %>%
  select(-avg_ssp126, -avg_ssp585)
  
# Just a check - not all the scinames in Juliano's future climate data join to artis because they are organized by sciname and eez. So not every sciname will join to the artis sciname because while Juliano's sciname might be in artis, it might not be in the same eez too.
  full_join(
    consumption_sciname %>% mutate(artis = TRUE),
    df1 %>%
      mutate(fcd = TRUE),
    by = c("eez_iso3c", "sciname_hs_modified" = "sciname")
  ) %>%
    filter(fcd == TRUE) %>%
    ungroup() %>%
    filter(is.na(artis), fcd == TRUE)
  
# Remove previous objects to keep data usage small
rm(consumption_sciname, sciname_taxa, consumption,
   averages_class, averages_family, averages_genus,
   averages_order, averages_phylum, averages_subfamily,
   df, lookup_table, sciname, sciname_taxa, test_data)
gc() # Garbage collection to clean up storage

# Find the sum of the interpolated scinames' live_weights
interpolated_future_data %>% 
  filter(!is.na(ssp126)) %>% distinct(sciname_hs_modified)


# Just Juliano's data
interpolated_future_data %>% 
  filter(str_detect(sciname_hs_modified, " "), !is.na(ssp126)) %>% 
  summarize(sum_live_weight_t = sum(live_weight_t)) 


# No values
interpolated_future_data %>% 
  filter(is.na(ssp126)) %>% 
  group_by(sciname_hs_modified, eez_iso3c) %>% 
  summarize(sum_live_weight_t = sum(live_weight_t)) %>%
  arrange(-sum_live_weight_t)

unique(df1$sciname) %>% length()

consumption_future %>% distinct(sciname_hs_modified)

# consumption_future %>%
#   left_join(sciname, by = c("sciname_hs_modfied" = "sciname")) %>%
#   filter(class == "actinopterygii",
#          is.na(ssp126)) 
```

```{r derive exposure measurements via disaggregated future climate data}
### BRINGING IN interpolated_future_data from 98_Testing_Future_Catch_Disaggregation ###

# Join future data on consumption data
consumption_future <- left_join(interpolated_future_data, df1, by = c("sciname_hs_modified" = "sciname", "eez_iso3c"))

# Pivot dataset to longer to make multiscenario visualization easier
consumption_future <- interpolated_future_data %>%
  pivot_longer(cols = c(`ssp126`,
                        `ssp585`), 
               names_to = "scenario",
               values_to = "future_change_catch")

#Add in variable later
# consumer_foreign_dependencies


# NOTE: Commenting out first filter will give the entire consumption portfolio. Commenting out the second filter will give only imports.

# Get % change in stock composition by country
consumer_stock_change_pre <- consumption_future %>% 
  # filter(consumer_iso3c != producer_iso3c, # Only include importing countries; drop NAs
  #        !is.na(live_weight_t),
  #        !is.na(future_change_catch)) %>%
  filter(!is.na(live_weight_t),
         !is.na(future_change_catch)) %>%
  mutate(future_change_catch = case_when( # Convert percentage to proportion
    future_change_catch > 0 ~ (future_change_catch / 100) + 1,
    future_change_catch < 0 ~ 1 - ((future_change_catch / 100) * -1), 
    future_change_catch == 0 ~ 1)) %>%
  # group_by(consumer_iso3c, scenario, sciname_hs_modified) %>%
  mutate(change_in_stock = live_weight_t * future_change_catch)
  
# Use future weights to calculate % change in weight by country
consumer_stock_change <- consumer_stock_change_pre %>% 
  group_by(consumer_iso3c, scenario) %>%
    summarize(change_in_stock = sum(change_in_stock),
              live_weight_t = sum(live_weight_t)) %>%
    mutate(pct_change = 100 * ((change_in_stock - live_weight_t) / live_weight_t))

# Write to csv
write_csv(consumer_stock_change, "../output/consumer_stock_change.csv")

# Remove previous objects to keep data usage small
rm(df1, interpolated_future_data, consumer_stock_change_pre)
gc() # Garbage collection to clean up storage
```

```{r add in sensitivity data}
# Read in supply importance data
aquatic_reliance <- read_csv("../data/sensitivity/fao_aquatic_reliance_source.csv") %>%
filter(!(data_source == "old FBS" & year %in% 2010:2013))


# Create the output directory if it doesn't exist
output_dir <- "../data/sensitivity/annual_marine_capture_foreign_reliances"
if (!dir.exists(output_dir)) {
  dir.create(output_dir)
}

# Loop through each year 1996 to 2019
for (yr in 1996:2019) {
  
  # Calculate marine capture aquatic animal reliance
  aa_reliance <- aquatic_reliance %>%
    filter(
      year == yr,
      habitat == "marine",
      method == "capture",
      food_group == "aquatic"
    ) %>%
    group_by(iso3c) %>%
    summarize(aa_reliance_pct = sum(prop_animal_protein, na.rm = TRUE)) %>%
    ungroup()
  
  # Define output filename
  output_file <- file.path(output_dir, paste0("aa_reliance_", yr, ".csv"))
  
  # Save to CSV
  write_csv(aa_reliance, output_file)
  
  message("Saved: ", output_file)
}

# Remove previous objects to keep data usage small
rm(supply_importance)
gc() # Garbage collection to clean up storage
```


```{r process adaptive capacity data}
# Get ARTIS consuming countries (For identifying data coverage)
# changed consumption to consumption_future
consuming_countries <- consumption_future %>%
  filter(consumer_iso3c != producer_iso3c) %>%
  distinct(consumer_iso3c) %>%
  mutate(artis = 1)

country_coverage <- function(data2, join_by = "") {
  # Full join ARTIS countries + AC countries
  data <- full_join(consuming_countries, data2 %>% 
            mutate(gdp_coverage = 1), 
            by = c("consumer_iso3c" = join_by)) %>%
  filter(is.na(gdp_coverage) & artis == 1)
  
  # Look at which countries are missing
  missing_countries <- data %>%
    pull(consumer_iso3c)
  
  return(missing_countries)
}

##########
# ASSETS #
##########

# sanitation
sanitation <- read_csv("../data/adaptive capacity/assets/sanitation.csv")

sanitation_clean <- sanitation %>%
  filter(Indicator_Code == "SH_STA_BASS_ZS", Time_Period == 2019)

a <- country_coverage(sanitation_clean, join_by = "Geography_Code")

# gdp
gdp <- read_csv("../data/adaptive capacity/assets/gdp.csv")

gdp_clean <- gdp %>%
  select(`Country Code`, `2019`) %>%
  filter(!is.na(`2019`))

b <- country_coverage(gdp_clean, join_by = "Country Code")

# trade standardized by gdp
trade_gdp <- read_csv("../data/adaptive capacity/assets/trade_gdp.csv")

trade_gdp_clean <- trade_gdp %>%
  filter(`Indicator Code` == "NE.TRD.GNFS.ZS") %>%
  select(`Country Code`,`2019`) %>%
  filter(!is.na(`2019`))

c <- country_coverage(trade_gdp_clean, join_by = "Country Code")



###############
# FLEXIBILITY #
###############

# life expectancy
life_expectancy <- read_csv("../data/adaptive capacity/flexibility/life_expectancy_at_birth.csv")

life_expectancy_clean <- life_expectancy %>%
  filter(`Indicator Code` == "SP.DYN.LE00.IN") %>%
  select(`Country Code`,`2019`) %>%
  filter(!is.na(`2019`))

d <- country_coverage(life_expectancy_clean, join_by = "Country Code")

# supermarkets per 100000
supermarkets <- read_csv("../data/adaptive capacity/flexibility/supermarkets_per_100000.csv")

supermarkets_clean <- supermarkets %>%
  mutate(iso3c = countrycode(Region, origin = 'country.name', destination = 'iso3c')) %>%
  select(iso3c, `2019`) %>%
  filter(!is.na(2019))

e <- country_coverage(supermarkets_clean, join_by = "iso3c")

# prop labor force
total_labor_force <- read_csv("../data/adaptive capacity/flexibility/total_labor_force.csv")
total_population <- read_csv("../data/adaptive capacity/flexibility/total_population.csv")

total_population_clean <- total_population %>%
  select(`Country Code`, `2019`) %>%
  rename(total_pop_2019 = "2019")

prop_population_clean <- left_join(total_labor_force, total_population_clean, by = "Country Code") %>%
  select(`Country Code`, `2019`, total_pop_2019) %>%
  mutate(prop_labor = `2019` / total_pop_2019) %>%
  filter(!is.na(prop_labor))

f <- country_coverage(prop_population_clean, join_by = "Country Code")



############
# LEARNING #
############

# Human capital index
hci <- read_csv("../data/adaptive capacity/learning/HCIData.csv")

hci_clean <- hci %>%
  filter(`Indicator Name` == "Human Capital Index (HCI) (scale 0-1)") %>%
  select(`Country Code`, `2018`) %>%
  filter(!is.na(`2018`))
  
h <- country_coverage(hci_clean, join_by = "Country Code")

#######################
# SOCIAL ORGANIZATION #
#######################

# government effectiveness
government_effectiveness <- read_csv("../data/adaptive capacity/social organization/government_effectiveness_percentile.csv")

government_effectiveness_clean <- government_effectiveness %>%
  filter(`Indicator ID` == "WB.WWGI.GE.PER.RNK") %>%
  select(`Economy ISO3`,`2019`) %>%
  filter(!is.na(`2019`))

i <- country_coverage(government_effectiveness_clean, join_by = "Economy ISO3")

# Food safety capacity
fsc <- read_csv("../data/adaptive capacity/social organization/food-systems-dashboard-2025-03-04.csv")

fsc_clean <- fsc %>%
  filter(`Start Year` == 2019 | `End Year` == 2019)

j <- country_coverage(fsc_clean, join_by = "ISO3")

# Rule of law
rol <- read_csv("../data/adaptive capacity/social organization/WB-WWGI.csv")

rol_clean <- rol %>% 
  filter(Indicator == "Rule of Law: Percentile Rank") %>%
  select(`Economy ISO3`, `Indicator`, `2019`)

k <- country_coverage(rol_clean, join_by = "Economy ISO3")
```

```{r}
library(dplyr)
library(readr)
library(countrycode)
library(purrr)
library(rlang)

#---------------------------------------------
# Create output directory
#---------------------------------------------
output_dir <- "../data/adaptive capacity/annual_adaptive_capacity"
if (!dir.exists(output_dir)) dir.create(output_dir)

years <- 1996:2019

#---------------------------------------------
# Safe wrapper for data processing
#---------------------------------------------
safe_process <- function(expr, label) {
  tryCatch(
    suppressWarnings(expr),
    error = function(e) {
      message("‚ö†Ô∏è Skipping ", label, " ‚Äî ", conditionMessage(e))
      return(NULL)
    }
  )
}

#---------------------------------------------
# Loop over each year
#---------------------------------------------
for (yr in years) {
  message("\nüìÖ Processing year: ", yr)
  year_col <- as.character(yr)

  ##################
  # --- ASSETS --- #
  ##################

  sanitation_clean <- safe_process({
    df <- read_csv("../data/adaptive capacity/assets/sanitation.csv", show_col_types = FALSE)
    df %>%
      filter(Indicator_Code == "SH_STA_BASS_ZS", Time_Period == yr) %>%
      select(Geography_Code, Value) %>%
      rename(iso3c = Geography_Code, sanitation = Value)
  }, "sanitation")

  gdp_clean <- safe_process({
    df <- read_csv("../data/adaptive capacity/assets/gdp.csv", show_col_types = FALSE)
    if (!(year_col %in% names(df))) return(NULL)
    df %>%
      select(`Country Code`, !!sym(year_col)) %>%
      rename(iso3c = `Country Code`, gdp = !!sym(year_col)) %>%
      filter(!is.na(gdp))
  }, "gdp")

  trade_gdp_clean <- safe_process({
    df <- read_csv("../data/adaptive capacity/assets/trade_gdp.csv", show_col_types = FALSE)
    if (!(year_col %in% names(df))) return(NULL)
    df %>%
      filter(`Indicator Code` == "NE.TRD.GNFS.ZS") %>%
      select(`Country Code`, !!sym(year_col)) %>%
      rename(iso3c = `Country Code`, trade_gdp = !!sym(year_col)) %>%
      filter(!is.na(trade_gdp)) %>%
      rename(gdp_trade = trade_gdp)
  }, "trade_gdp")

  ##########################
  # --- FLEXIBILITY --- #
  ##########################

  life_expectancy_clean <- safe_process({
    df <- read_csv("../data/adaptive capacity/flexibility/life_expectancy_at_birth.csv", show_col_types = FALSE)
    if (!(year_col %in% names(df))) return(NULL)
    df %>%
      filter(`Indicator Code` == "SP.DYN.LE00.IN") %>%
      select(`Country Code`, !!sym(year_col)) %>%
      rename(iso3c = `Country Code`, life_expectancy = !!sym(year_col)) %>%
      filter(!is.na(life_expectancy))
  }, "life_expectancy")

  supermarkets_clean <- safe_process({
    df <- read_csv("../data/adaptive capacity/flexibility/supermarkets_per_100000.csv", show_col_types = FALSE)
    df$Region <- iconv(df$Region, from = "UTF-8", to = "UTF-8", sub = "")
    if (!(year_col %in% names(df))) {
      message("‚ö†Ô∏è No supermarkets data for ", yr, ", skipping.")
      return(NULL)
    }
    df %>%
      mutate(iso3c = countrycode(Region, origin = "country.name", destination = "iso3c", warn = FALSE)) %>%
      select(iso3c, !!sym(year_col)) %>%
      rename(supermarkets = !!sym(year_col)) %>%
      filter(!is.na(supermarkets))
  }, "supermarkets")

  prop_population_clean <- safe_process({
    lf <- read_csv("../data/adaptive capacity/flexibility/total_labor_force.csv", show_col_types = FALSE)
    pop <- read_csv("../data/adaptive capacity/flexibility/total_population.csv", show_col_types = FALSE)
    if (!(year_col %in% names(lf)) || !(year_col %in% names(pop))) return(NULL)
    lf %>%
      select(`Country Code`, !!sym(year_col)) %>%
      rename(labor_force = !!sym(year_col)) %>%
      left_join(pop %>% select(`Country Code`, !!sym(year_col)) %>% rename(total_pop = !!sym(year_col)), by = "Country Code") %>%
      mutate(prop_labor = labor_force / total_pop) %>%
      rename(iso3c = `Country Code`) %>%
      select(iso3c, prop_labor) %>%
      filter(!is.na(prop_labor))
  }, "prop_labor")

  ###################
  # --- LEARNING --- #
  ###################

  hci_clean <- safe_process({
    df <- read_csv("../data/adaptive capacity/learning/HCIData.csv", show_col_types = FALSE)
    yr_hci <- ifelse(yr <= 2018, year_col, "2018")
    if (!(yr_hci %in% names(df))) return(NULL)
    df %>%
      filter(`Indicator Name` == "Human Capital Index (HCI) (scale 0-1)") %>%
      select(`Country Code`, !!sym(yr_hci)) %>%
      rename(iso3c = `Country Code`, hci = !!sym(yr_hci)) %>%
      filter(!is.na(hci))
  }, "hci")

  ####################################
  # --- SOCIAL ORGANIZATION --- #
  ####################################

  government_effectiveness_clean <- safe_process({
    df <- read_csv("../data/adaptive capacity/social organization/government_effectiveness_percentile.csv", show_col_types = FALSE)
    yr_ge <- ifelse(yr >= 1996, year_col, "1996")
    if (!(yr_ge %in% names(df))) return(NULL)
    df %>%
      filter(`Indicator ID` == "WB.WWGI.GE.PER.RNK") %>%
      select(`Economy ISO3`, !!sym(yr_ge)) %>%
      rename(iso3c = `Economy ISO3`, gov_effectiveness = !!sym(yr_ge)) %>%
      filter(!is.na(gov_effectiveness))
  }, "government_effectiveness")

  fsc_clean <- safe_process({
    df <- read_csv("../data/adaptive capacity/social organization/food-systems-dashboard-2025-03-04.csv", show_col_types = FALSE)
    
    df <- df %>%
      filter(`Start Year` == yr | `End Year` == yr) %>%
      select(ISO3, `Value`) %>%
      rename(iso3c = ISO3, fsc = `Value`)
    
    if ((nrow(df) == 0)) return(NULL)
    
    df
  }, "food_safety_capacity")

  rol_clean <- safe_process({
    df <- read_csv("../data/adaptive capacity/social organization/WB-WWGI.csv", show_col_types = FALSE)
    yr_rol <- ifelse(yr >= 1996, year_col, "1996")
    if (!(yr_rol %in% names(df))) return(NULL)
    df %>%
      filter(Indicator == "Rule of Law: Percentile Rank") %>%
      select(`Economy ISO3`, !!sym(yr_rol)) %>%
      rename(iso3c = `Economy ISO3`, rol = !!sym(yr_rol)) %>%
      filter(!is.na(rol))
  }, "rol")

  #######################################
  # --- JOIN ALL ADAPTIVE CAPACITY --- #
  #######################################

  datasets <- list(
    sanitation_clean,
    gdp_clean,
    trade_gdp_clean,
    life_expectancy_clean,
    supermarkets_clean,
    prop_population_clean,
    hci_clean,
    government_effectiveness_clean,
    fsc_clean,
    rol_clean
  ) %>% compact()

  if (length(datasets) == 0) {
    message("‚ö†Ô∏è No adaptive capacity data available for year ", yr, " ‚Äî skipping.")
    next
  }

  adaptive_capacity <- reduce(datasets, full_join, by = "iso3c") %>%
    mutate(year = yr)

  output_file <- file.path(output_dir, paste0("adaptive_capacity_", yr, ".csv"))
  write_csv(adaptive_capacity, output_file)
  message("‚úÖ Saved: ", output_file)
}

message("\nüéâ Finished processing all years 1996‚Äì2019 safely.")
```


```{r Join e / s / ac to prep for risk calculaton}
library(dplyr)
library(readr)
library(arrow)
library(purrr)

#---------------------------------------------
# Setup
#---------------------------------------------
years <- 1996:2019
ac_dir <- "../data/adaptive capacity/annual_adaptive_capacity"
output_dir <- "../data/annual_e_s_ac_data"

if (!dir.exists(output_dir)) dir.create(output_dir)

#---------------------------------------------
# Loop through each year and build e_s_ac_data
#---------------------------------------------
for (yr in years) {
  message("\nüìÖ Processing e/s/ac for year: ", yr)

  ac_file <- file.path(ac_dir, paste0("adaptive_capacity_", yr, ".csv"))

  # Skip if adaptive capacity data for this year is missing
  if (!file.exists(ac_file)) {
    message("‚ö†Ô∏è No adaptive capacity data for ", yr, " ‚Äî skipping.")
    next
  }

  # Load adaptive capacity data
  ac_data <- read_csv(ac_file, show_col_types = FALSE)

  # Load aquatic animal reliance for this year
  aa_reliance_year <- safe_process({
    aquatic_reliance %>%
      filter(year == yr, habitat == "marine", method == "capture", food_group == "aquatic") %>%
      group_by(iso3c) %>%
      summarize(aa_reliance_pct = sum(prop_animal_protein, na.rm = TRUE)) %>%
      ungroup() %>%
      rename(consumer_iso3c = iso3c)
  }, "aa_reliance")

  # Skip if all critical components missing
  if (is.null(ac_data) && is.null(aa_reliance_year) && is.null(exposure_year)) {
    message("‚ö†Ô∏è No e/s/ac data available for ", yr, " ‚Äî skipping.")
    next
  }

  #---------------------------------------------
  # Join everything together
  #---------------------------------------------
  e_s_ac_data <- ac_data %>%
    rename(consumer_iso3c = iso3c) %>%
    left_join(aa_reliance_year, by = "consumer_iso3c") %>%
    left_join(consumer_stock_change, by = "consumer_iso3c") %>%
    mutate(year = yr)

  #---------------------------------------------
  # Save to Parquet
  #---------------------------------------------
  output_file <- file.path(output_dir, paste0("e_s_ac_data_", yr, ".parquet"))
  write_parquet(e_s_ac_data, output_file)
  message("‚úÖ Saved: ", output_file)
}

message("\nüéâ Finished joining all e/s/ac datasets from 1996‚Äì2019.")
```
